{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#OAuth Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will try to scrape twitter data and do a tf-idf analysis on that (src-uwes twitter analysis). We will need OAuth authentication, and we will follow a similar approach as detailed in the yelp analysis notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jsonpickle, operator,json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import oauth2 as oauth\n",
    "import urllib2 as urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now need twitter api access. The following steps as available online will help you set up your twitter account and access the live 1% stream.\n",
    "\n",
    "1. Create a twitter account if you do not already have one.\n",
    "2. Go to https://dev.twitter.com/apps and log in with your twitter credentials.\n",
    "3. Click \"Create New App\"\n",
    "4. Fill out the form and agree to the terms. Put in a dummy website if you don't have one you want to use.\n",
    "5. On the next page, click the \"API Keys\" tab along the top, then scroll all the way down until you see the section \"Your Access Token\"\n",
    "6. Click the button \"Create My Access Token\". You can Read more about Oauth authorization online. \n",
    "\n",
    "Save the details of api_key, api_secret, access_token_key, access_token_secret in your vaule directory and load it in the notebook as shown in yelpSample notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/mgalarny/VaultDSE')\n",
    "import twitterKeys\n",
    "api_key,api_secret,access_token_key,access_token_secret=twitterKeys.getkeys()\n",
    "\n",
    "_debug = 0\n",
    "\n",
    "oauth_token    = oauth.Token(key=access_token_key, secret=access_token_secret)\n",
    "oauth_consumer = oauth.Consumer(key=api_key, secret=api_secret)\n",
    "\n",
    "signature_method_hmac_sha1 = oauth.SignatureMethod_HMAC_SHA1()\n",
    "\n",
    "http_method = \"GET\"\n",
    "\n",
    "http_handler  = urllib.HTTPHandler(debuglevel=_debug)\n",
    "https_handler = urllib.HTTPSHandler(debuglevel=_debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a twitter request method which will use the above user logins to sign, and open a twitter stream request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTwitterStream(url, method, parameters):\n",
    "  req = oauth.Request.from_consumer_and_token(oauth_consumer,\n",
    "                                             token=oauth_token,\n",
    "                                             http_method=http_method,\n",
    "                                             http_url=url, \n",
    "                                             parameters=parameters)\n",
    "\n",
    "  req.sign_request(signature_method_hmac_sha1, oauth_consumer, oauth_token)\n",
    "\n",
    "  headers = req.to_header()\n",
    "\n",
    "  if http_method == \"POST\":\n",
    "    encoded_post_data = req.to_postdata()\n",
    "  else:\n",
    "    encoded_post_data = None\n",
    "    url = req.to_url()\n",
    "\n",
    "  opener = urllib.OpenerDirector()\n",
    "  opener.add_handler(http_handler)\n",
    "  opener.add_handler(https_handler)\n",
    "\n",
    "  response = opener.open(url, encoded_post_data)\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the above function to request a response as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we will test the above function for a sample data provided by twitter stream here -  \n",
    "url = \"https://stream.twitter.com/1/statuses/sample.json\"\n",
    "parameters = []\n",
    "response = getTwitterStream(url, \"GET\", parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which will take a url and return the top 10 lines returned by the twitter stream\n",
    "\n",
    "** Note ** The response returned needs to be intelligently parsed to get the text data which correspond to actual tweets. This part can be done in a number of ways and you are encouraged to try different approaches to parse the response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetchData(url):\n",
    "    response = getTwitterStream(url, \"GET\", [])\n",
    "    lines = response.read()\n",
    "    allinfo = jsonpickle.loads(lines)\n",
    "    statuses = allinfo['statuses']\n",
    "    print 'Stream'\n",
    "    print url.split('/')[-1][14:]\n",
    "    print '\\n'\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            print i+1\n",
    "            print statuses[i]['text'],'\\n'\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream\n",
      "UCSD\n",
      "\n",
      "\n",
      "1\n",
      "RT @Jazz88: RETWEET til 8am PT to ENTER Pair of Seats CONTEST!&gt; Mark Dresser Septet @TheLoftatUCSD 12/11&gt;https://t.co/DrQjjn7ubg https://t.‚Ä¶ \n",
      "\n",
      "2\n",
      "RT @Jazz88: RETWEET til 8am PT to ENTER Pair of Seats CONTEST!&gt; Mark Dresser Septet @TheLoftatUCSD 12/11&gt;https://t.co/DrQjjn7ubg https://t.‚Ä¶ \n",
      "\n",
      "3\n",
      "RT @Jazz88: RETWEET til 8am PT to ENTER Pair of Seats CONTEST!&gt; Mark Dresser Septet @TheLoftatUCSD 12/11&gt;https://t.co/DrQjjn7ubg https://t.‚Ä¶ \n",
      "\n",
      "4\n",
      "RT @NetworkFact: Spectral graph theory by Fan Chung https://t.co/6B6PfMAFfo \n",
      "\n",
      "5\n",
      "RT @UCSDtritons: SWIM: @UCSDSwimDiveüèä dropped dual meets in Santa Barbara Sat. Up next is @a3performance Invite Nov. 19-21. https://t.co/8n‚Ä¶ \n",
      "\n",
      "6\n",
      "TAT helps woman with cancer have less stress, more joy and improved posture. https://t.co/xPrSppMOLT #acepblog #energypsych \n",
      "\n",
      "7\n",
      "RT @Natalya_Gallo: \"Who, if not us? When, if not now?\" Hoping for an ambitious climate agreement here in Paris at #COP21 2 days left. #ucsd‚Ä¶ \n",
      "\n",
      "8\n",
      "RT @pasquale_rossi: @AdviseOnly si parla di razionamento credito(e impatto sull'immobiliare)J.Stiglitz &amp; A.Weiss https://t.co/05RiVzoTt9 ht‚Ä¶ \n",
      "\n",
      "9\n",
      "RT @albpro: @luis261977 @ElHuffPost @sninobecerra Argumentos de peso (lastima en ingles)\n",
      "https://t.co/ZlZZyDhjlR\n",
      "https://t.co/TIp00LuuXw \n",
      "\n",
      "10\n",
      "@luis261977 @ElHuffPost @sninobecerra Argumentos de peso (lastima en ingles)\n",
      "https://t.co/ZlZZyDhjlR\n",
      "https://t.co/TIp00LuuXw \n",
      "\n",
      "Stream\n",
      "Donald Trump\n",
      "\n",
      "\n",
      "1\n",
      "#DonaldTrump wants to 'close the internet off in some ways' to stop children being rad... https://t.co/5rixOWEUX9 https://t.co/IkBZPhdOVz \n",
      "\n",
      "2\n",
      "RT @desusnice: This is why Donald Trump is polling so high https://t.co/FlRV8V37bm \n",
      "\n",
      "3\n",
      "RT @susetyopr: Gara-Gara Donald Trump, 5 Tokoh Ini Bersatu - https://t.co/FAWycasEIp https://t.co/hDzovleVTT \n",
      "\n",
      "4\n",
      "I wonder if they insult us every second of everyday? Do we forget Paris. they want to act with hatred. I say fight. https://t.co/6QdyRzZK5j \n",
      "\n",
      "5\n",
      "RT @DMReporter: HATE PREACHER: So many comments supporting Donald Trump‚Ä¶ soooo many comments. https://t.co/DDBcWalCyZ \n",
      "\n",
      "6\n",
      "RT @BuzzFeedUK: Here is Donald Trump being attacked by a Bald Eagle\n",
      "https://t.co/977TFS9fTQ https://t.co/lImbgSgppB \n",
      "\n",
      "7\n",
      "https://t.co/fSQjFiQSaK @NPR @anderskelto \n",
      "\n",
      "Muslims s/b banned not b/c of religion but rather because they are responsible for terror. \n",
      "\n",
      "8\n",
      "RT @SteveLTurner: Donald Trump: \"The police in London are terrified for their lives\" https://t.co/7wnfACgwOg \n",
      "\n",
      "9\n",
      "RT @Unnamedinsider: If you say 'Donald Trump' 3 times in a mirror, he appears and demands to see your birth certificate #TrumpFacts \n",
      "\n",
      "10\n",
      "RT @GMA: TOP STORY: Muhammad Ali responds to Donald Trump's Muslim ban proposal: https://t.co/Y38tW7IIiU https://t.co/4f24ZG4yBn \n",
      "\n",
      "Stream\n",
      "Syria\n",
      "\n",
      "\n",
      "1\n",
      "RT @Syriasonline: Militants from the Waer, Homs neighborhood taken  to Idlib, #Syria https://t.co/CzadIGLePt \n",
      "\n",
      "2\n",
      "RT @charlesfrith: Israel rescue ISIS from Syria. Yes folks another conspiracy theory is true. https://t.co/GJNeo3JyYk   https://t.co/D6Lthk‚Ä¶ \n",
      "\n",
      "3\n",
      "RT @MADBLACKTWINK: White people: All lives matter \n",
      "\n",
      "Syria: we got refugees in danger \n",
      "\n",
      "White people: new phone who dis \n",
      "\n",
      "4\n",
      "RT @Terror_Monitor: #SYRIA\n",
      "Director Najdat Anzour Making A Film To Exposes #Daesh Aka #ISIS/#ISIL Terror Group - Report. https://t.co/koWjg‚Ä¶ \n",
      "\n",
      "5\n",
      "ŸÑÿß ÿßŸÖÿ±ŸäŸÉÿß ŸàŸÑÿß ÿ±Ÿàÿ≥Ÿäÿß ŸàŸÑÿß ÿßŸÑÿØŸàŸÑ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÖÿ¨ÿ™ŸÖÿπŸá ÿ™ŸÇÿØÿ± ÿπŸÑŸâ ÿ≠ŸÑ ÿ≥Ÿäÿßÿ≥Ÿä ŸÅŸä #ÿ≥Ÿàÿ±Ÿäÿß\n",
      ".\n",
      "ÿπŸÜÿØŸÖÿß ÿ™ŸÉŸàŸÜŸàÿß ÿπŸÑŸâ ÿßŸÑÿ£ÿ±ÿ∂ Ÿàÿ™ÿ¥ÿßŸáÿØŸàŸÜ ŸÖÿßŸäÿ≠ÿØÿ´\n",
      ".\n",
      "ÿ≥ÿ™ÿπÿ±ŸÅŸàŸÜ ÿ≠ŸÇŸäŸÇÿ© Ÿáÿ∞ÿß ÿßŸÑŸÉŸÑÿßŸÖ \n",
      "\n",
      "6\n",
      "RT @GeorgeAylett: A group of ex-soldiers have thrown away their medals outside Downing Street in protest of UK decision to bomb Syria. http‚Ä¶ \n",
      "\n",
      "7\n",
      "RT @mayushka2002: @WNTonight @realDonaldTrump @LIVE_COVERAGE @BarackObama @PutinRF_Eng American must stop ISIS now or will see other 911or ‚Ä¶ \n",
      "\n",
      "8\n",
      "ISIS \"Poster Girl\" Beaten to Death for Trying to Escape Syria https://t.co/7uPxSezTEr https://t.co/gz0WCNkRqw|v.L \n",
      "\n",
      "9\n",
      "RT @STWuk: #StopBombingSyria national demo | 12Dec London | TRANSPORT FROM ROUND UK | Updates here: https://t.co/yJ6ifeBzSQ https://t.co/Vl‚Ä¶ \n",
      "\n",
      "10\n",
      "RT @iran_policy: A united front is needed to defeat Islamic extremism\n",
      "https://t.co/JU8QdaDkH1\n",
      "#Iran #Iraq #Syria https://t.co/m8EEeN54td \n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = ['UCSD', 'Donald Trump', 'Syria']\n",
    "\n",
    "for query in queries:\n",
    "    #We can also request twitter stream data for specific search parameters as follows\n",
    "    url= \"https://api.twitter.com/1.1/search/tweets.json?q=\" + query\n",
    "    fetchData(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the fetchData function to fetch latest live stream data for following search queries and output the first 5 lines\n",
    "\n",
    "1. \"UCSD\"\n",
    "2. \"Donald Trump\"\n",
    "3. \"Syria\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF###\n",
    "\n",
    "tf‚Äìidf, short for term frequency‚Äìinverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.It is among the most regularly used statistical tool for word cloud analysis. You can read more about it online (https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "We base our analysis on the following\n",
    "\n",
    "1. The weight of a term that occurs in a document is simply proportional to the term frequency\n",
    "2. The specificity of a term can be quantified as an inverse function of the number of documents in which it occurs\n",
    "\n",
    "For this question we will perform tf-idf analysis o the stream data we retrieve for a given search parameter. Perform the steps below\n",
    "\n",
    "1. use the twitterreq function to search for the query \"syria\" and save the top 200 lines in the file twitterStream.txt\n",
    "2. load the saved file and output the count of occurrences for each term. This will be your term frequency\n",
    "3. Calculate the inverse document frequency for each of the term in the output above.\n",
    "4. Divide the term frequency for each of the term by corresponding inverse document frequency.\n",
    "5. Sort the terms in the descending order based on their term freq/inverse document freq scores \n",
    "6. Print the top 10 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Stream file generated\n"
     ]
    }
   ],
   "source": [
    "#1. use the twitterreq function to search for the query \"syria\" and save the top 200 lines in the file twitterStream.txt\n",
    "writer = open('twitterStream.txt', 'a') \n",
    "url= \"https://api.twitter.com/1.1/search/tweets.json?q=\"+\"syria\"\n",
    "response = getTwitterStream(url, \"GET\", [])\n",
    "lines = response.read()\n",
    "j = json.loads(lines)\n",
    "h = j['statuses']\n",
    "for i in range(100):\n",
    "    try:\n",
    "        writer.write(h[i]['text'].replace('\\n',' ')+'\\n\\n')\n",
    "    except:\n",
    "        continue\n",
    "writer.close()\n",
    "\n",
    "print 'Twitter Stream file generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency:\n",
      "\n",
      "\n",
      "{'all': 1, 'signatures': 1, 'just': 1, 'https://t.co/7upxsezter': 1, 'https://t.co/peavqp2u8f': 1, 'over': 1, 'https://t.co/pwayryknaf': 1, 'vetted': 1, 'front': 1, 'its': 1, 'bombing': 1, 'death': 1, 'paris': 1, '@rt_com:': 1, 'torn': 1, 'https://t.co/m8eeen54td': 1, 'to': 8, 'only': 1, 'van': 1, 'policy': 1, 'has': 1, 'https://t.co/8hbyib7kbb': 1, 'get': 1, 'stop': 1, 'none': 1, '#iran': 2, '#iraq': 2, '#bataclan': 2, 'new': 1, 'not': 3, 'identified': 2, 'these': 1, '#gaza': 1, '@ramseyinho:': 1, 'ban': 1, 'river': 1, 'refugees': 1, 'side': 1, 'dis': 1, 'neighborhood': 1, '@teamtrump2016': 1, 'people': 2, 'idlib': 1, 'homs': 1, 'are': 1, 'escape': 1, 'girl': 1, 'guess': 1, 'https://t.co/u2pubd5lrf': 1, 'rt': 7, 'said': 1, '@manutd': 1, 'beaten': 1, '@syriasonline:': 1, 'weapons': 1, 'https://t.co/vjgd9nfwww': 1, 'got': 1, 'gov': 1, 'public': 1, 'be': 2, 'we': 2, 'iran': 1, 'bc': 1, '\"poster': 1, '#russia': 1, 'https://t.co/mkoj4uisbz': 1, '#israel': 1, 'frenchman': 2, 'on': 1, 'about': 2, 'of': 3, 'days': 1, '#palestine': 1, 'muslims': 1, 'defeat': 1, 'syria': 8, 'blood': 1, 'winner': 1, 'danger': 1, 'win': 1, 'manage': 1, 'one': 1, '#usa': 1, '#eu': 1, 'done': 1, 'open': 1, 'trump': 2, 'story': 2, 'https://t.co/gz0wcnkrqw|v.l': 1, 'from': 2, 'cares': 1, \"it's\": 1, '#auspol': 1, '@iran_policy:': 1, 'needed': 1, 'fought': 2, 'extremism': 1, 'taken': 1, 'white': 2, 'https://t.co/mlywljrxcz': 1, 'war': 4, 'gaal': 1, '#middleeast': 1, 'that': 1, 'but': 4, 'phone': 1, 'lives': 1, 'trying': 1, 'those': 1, '2(?)': 1, '#syria': 5, 'isis': 1, 'this': 2, 'will': 2, 'matter': 1, 'can': 1, 'country': 1, '#bds': 1, 'pm': 1, '@madblacktwink:': 1, '#feedly': 1, 'aerial': 1, 'want': 1, 'is': 4, '400k+': 1, 'as': 3, 'at': 1, 'have': 1, 'in': 6, \"gov't\": 1, 'their': 1, 'if': 1, 'united': 1, 'against': 1, 'https://t.co/czadiglept': 1, 'role': 1, 'best': 1, 'party': 1, 'https://t.co/bob8ameh2q': 1, 'https://t.co/ju8qdadkh1': 1, 'syria:': 1, 'who': 4, 'waer': 1, \"let's\": 1, 'islamic': 1, 'militants': 1, 'important': 1, '@arnews1936:': 1, 'opinion': 1, 'nothing': 1, 'a': 4, '@mackylucifera:': 1, 'for': 1, 'third': 2, 'attacker': 2, 'i': 1, 'no': 1, 'obviously': 1, 'so': 1, 'the': 6, '#uk': 1, 'attacking': 1, 'people:': 2}\n"
     ]
    }
   ],
   "source": [
    "#2. load the saved file and output the count of occurrences for each term. This will be your term frequency\n",
    "\n",
    "def tf(name):\n",
    "    '''Term Frequency'''\n",
    "    char = '.,?\"'\n",
    "    text = open(name, 'r')\n",
    "    line = text.read()\n",
    "    text.close()\n",
    "    word_list=line.lower().split()\n",
    "    count_dict = {}\n",
    "    for word in word_list:\n",
    "        if word[-1] in char:\n",
    "            word = word[:-1]\n",
    "        if word not in count_dict:\n",
    "            count_dict[word]=0\n",
    "    for word in word_list:\n",
    "        if word[-1] in char:\n",
    "            word = word[:-1]\n",
    "        count_dict[word]+=1\n",
    "    return count_dict\n",
    "\n",
    "name = 'twitterStream.txt'\n",
    "tf = tf(name)\n",
    "\n",
    "print 'Term Frequency:\\n\\n'\n",
    "print tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Document Frequency:\n",
      "\n",
      "\n",
      "{'all': 1.4471580313422192, 'signatures': 1.4471580313422192, 'just': 1.4471580313422192, 'https://t.co/7upxsezter': 1.4471580313422192, 'https://t.co/peavqp2u8f': 1.4471580313422192, 'over': 1.4471580313422192, 'https://t.co/pwayryknaf': 1.4471580313422192, 'vetted': 1.4471580313422192, 'front': 1.4471580313422192, 'its': 1.4471580313422192, 'bombing': 1.4471580313422192, 'death': 1.4471580313422192, 'paris': 1.4471580313422192, '@rt_com:': 1.4471580313422192, 'torn': 1.4471580313422192, 'https://t.co/m8eeen54td': 1.4471580313422192, 'to': 0.6020599913279624, 'only': 1.4471580313422192, 'van': 1.4471580313422192, 'policy': 1.4471580313422192, 'has': 1.4471580313422192, 'https://t.co/8hbyib7kbb': 1.4471580313422192, 'get': 1.4471580313422192, 'stop': 1.4471580313422192, 'none': 1.4471580313422192, '#iran': 1.146128035678238, '#iraq': 1.146128035678238, '#bataclan': 1.146128035678238, 'new': 1.4471580313422192, 'not': 0.97003677662255683, 'identified': 1.146128035678238, 'these': 1.4471580313422192, '#gaza': 1.4471580313422192, '@ramseyinho:': 1.4471580313422192, 'ban': 1.4471580313422192, 'river': 1.4471580313422192, 'refugees': 1.4471580313422192, 'side': 1.4471580313422192, 'dis': 1.4471580313422192, 'neighborhood': 1.4471580313422192, '@teamtrump2016': 1.4471580313422192, 'people': 1.146128035678238, 'idlib': 1.4471580313422192, 'homs': 1.4471580313422192, 'are': 1.4471580313422192, 'escape': 1.4471580313422192, 'girl': 1.4471580313422192, 'guess': 1.4471580313422192, 'https://t.co/u2pubd5lrf': 1.4471580313422192, 'rt': 0.6020599913279624, 'said': 1.4471580313422192, '@manutd': 1.4471580313422192, 'beaten': 1.4471580313422192, '@syriasonline:': 1.4471580313422192, 'weapons': 1.4471580313422192, 'https://t.co/vjgd9nfwww': 1.4471580313422192, 'got': 1.4471580313422192, 'gov': 1.4471580313422192, 'public': 1.4471580313422192, 'be': 1.146128035678238, 'we': 1.146128035678238, 'iran': 1.4471580313422192, 'bc': 1.4471580313422192, '\"poster': 1.4471580313422192, '#russia': 1.4471580313422192, 'https://t.co/mkoj4uisbz': 1.4471580313422192, '#israel': 1.4471580313422192, 'frenchman': 1.146128035678238, 'on': 1.4471580313422192, 'about': 1.146128035678238, 'of': 0.97003677662255683, 'days': 1.4471580313422192, '#palestine': 1.4471580313422192, 'muslims': 1.4471580313422192, 'defeat': 1.4471580313422192, 'syria': 0.54406804435027567, 'blood': 1.4471580313422192, 'winner': 1.4471580313422192, 'danger': 1.4471580313422192, 'win': 1.4471580313422192, 'manage': 1.4471580313422192, 'one': 1.4471580313422192, '#usa': 1.4471580313422192, '#eu': 1.4471580313422192, 'done': 1.4471580313422192, 'open': 1.4471580313422192, 'trump': 1.146128035678238, 'story': 1.4471580313422192, 'https://t.co/gz0wcnkrqw|v.l': 1.4471580313422192, 'from': 1.146128035678238, 'cares': 1.4471580313422192, \"it's\": 1.4471580313422192, '#auspol': 1.4471580313422192, '@iran_policy:': 1.4471580313422192, 'needed': 1.4471580313422192, 'fought': 1.146128035678238, 'extremism': 1.4471580313422192, 'taken': 1.4471580313422192, 'white': 1.4471580313422192, 'https://t.co/mlywljrxcz': 1.4471580313422192, 'war': 0.97003677662255683, 'gaal': 1.4471580313422192, '#middleeast': 1.4471580313422192, 'that': 1.4471580313422192, 'but': 0.84509804001425681, 'phone': 1.4471580313422192, 'lives': 1.4471580313422192, 'trying': 1.4471580313422192, 'those': 1.4471580313422192, '2(?)': 1.4471580313422192, '#syria': 0.74818802700620035, 'isis': 1.4471580313422192, 'this': 1.146128035678238, 'will': 1.146128035678238, 'matter': 1.4471580313422192, 'can': 1.4471580313422192, 'country': 1.4471580313422192, '#bds': 1.4471580313422192, 'pm': 1.4471580313422192, '@madblacktwink:': 1.4471580313422192, '#feedly': 1.4471580313422192, 'aerial': 1.4471580313422192, 'want': 1.4471580313422192, 'is': 0.84509804001425681, '400k+': 1.4471580313422192, 'as': 0.97003677662255683, 'at': 1.4471580313422192, 'have': 1.4471580313422192, 'in': 0.66900678095857558, \"gov't\": 1.4471580313422192, 'their': 1.4471580313422192, 'if': 1.4471580313422192, 'united': 1.4471580313422192, 'against': 1.4471580313422192, 'https://t.co/czadiglept': 1.4471580313422192, 'role': 1.4471580313422192, 'best': 1.4471580313422192, 'party': 1.4471580313422192, 'https://t.co/bob8ameh2q': 1.4471580313422192, 'https://t.co/ju8qdadkh1': 1.4471580313422192, 'syria:': 1.4471580313422192, 'who': 0.84509804001425681, 'waer': 1.4471580313422192, \"let's\": 1.4471580313422192, 'islamic': 1.4471580313422192, 'militants': 1.4471580313422192, 'important': 1.4471580313422192, '@arnews1936:': 1.4471580313422192, 'opinion': 1.4471580313422192, 'nothing': 1.4471580313422192, 'a': 0.97003677662255683, '@mackylucifera:': 1.4471580313422192, 'for': 1.4471580313422192, 'third': 1.146128035678238, 'attacker': 1.146128035678238, 'i': 1.4471580313422192, 'no': 1.4471580313422192, 'obviously': 1.4471580313422192, 'so': 1.4471580313422192, 'the': 0.97003677662255683, '#uk': 1.4471580313422192, 'attacking': 1.4471580313422192, 'people:': 1.4471580313422192}\n"
     ]
    }
   ],
   "source": [
    "#3. Calculate the inverse document frequency for each of the term in the output above.\n",
    "\n",
    "def idf(name):\n",
    "    '''Inverse Document Frequency'''\n",
    "    docs = open(name, 'r')\n",
    "    tot_docs = len(docs.readlines())\n",
    "    count_dict = {}\n",
    "    unique = []\n",
    "    docs.close()\n",
    "    \n",
    "    #Get all unique terms\n",
    "    docs = open(name, 'r')\n",
    "    char = '.,?\"'\n",
    "    text_list = docs.read().lower().split()\n",
    "    for word in text_list:\n",
    "        if word[-1] in char:\n",
    "            word = word[:-1]\n",
    "        if word not in unique:\n",
    "            unique.append(word)\n",
    "            count_dict[word] = 0\n",
    "    docs.close()\n",
    "    \n",
    "    #Term count in each doc\n",
    "    docs = open(name, 'r')\n",
    "    for line in docs.readlines():\n",
    "        new_line = []\n",
    "        for word in line.lower().split():\n",
    "            if word[-1] in char:\n",
    "                word = word[:-1]\n",
    "            new_line.append(word)\n",
    "        for term in unique:\n",
    "            if term[-1] in char:\n",
    "                term = term[:-1]\n",
    "            if term in new_line:\n",
    "                count_dict[term] += 1\n",
    "            else:\n",
    "                pass    \n",
    "    docs.close()\n",
    "    \n",
    "    #IDF calculation\n",
    "    for key in count_dict:\n",
    "        count_dict[key] = np.log10(float(tot_docs) / float(count_dict[key]))\n",
    "    \n",
    "    return count_dict\n",
    "        \n",
    "        \n",
    "name = 'twitterStream.txt'    \n",
    "idf = idf(name)\n",
    "print 'Inverse Document Frequency:\\n\\n'\n",
    "print idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency - Inverse Document Frequency:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\"poster': 1.4471580313422192,\n",
       " '#auspol': 1.4471580313422192,\n",
       " '#bataclan': 2.2922560713564759,\n",
       " '#bds': 1.4471580313422192,\n",
       " '#eu': 1.4471580313422192,\n",
       " '#feedly': 1.4471580313422192,\n",
       " '#gaza': 1.4471580313422192,\n",
       " '#iran': 2.2922560713564759,\n",
       " '#iraq': 2.2922560713564759,\n",
       " '#israel': 1.4471580313422192,\n",
       " '#middleeast': 1.4471580313422192,\n",
       " '#palestine': 1.4471580313422192,\n",
       " '#russia': 1.4471580313422192,\n",
       " '#syria': 3.7409401350310016,\n",
       " '#uk': 1.4471580313422192,\n",
       " '#usa': 1.4471580313422192,\n",
       " '2(?)': 1.4471580313422192,\n",
       " '400k+': 1.4471580313422192,\n",
       " '@arnews1936:': 1.4471580313422192,\n",
       " '@iran_policy:': 1.4471580313422192,\n",
       " '@mackylucifera:': 1.4471580313422192,\n",
       " '@madblacktwink:': 1.4471580313422192,\n",
       " '@manutd': 1.4471580313422192,\n",
       " '@ramseyinho:': 1.4471580313422192,\n",
       " '@rt_com:': 1.4471580313422192,\n",
       " '@syriasonline:': 1.4471580313422192,\n",
       " '@teamtrump2016': 1.4471580313422192,\n",
       " 'a': 3.8801471064902273,\n",
       " 'about': 2.2922560713564759,\n",
       " 'aerial': 1.4471580313422192,\n",
       " 'against': 1.4471580313422192,\n",
       " 'all': 1.4471580313422192,\n",
       " 'are': 1.4471580313422192,\n",
       " 'as': 2.9101103298676705,\n",
       " 'at': 1.4471580313422192,\n",
       " 'attacker': 2.2922560713564759,\n",
       " 'attacking': 1.4471580313422192,\n",
       " 'ban': 1.4471580313422192,\n",
       " 'bc': 1.4471580313422192,\n",
       " 'be': 2.2922560713564759,\n",
       " 'beaten': 1.4471580313422192,\n",
       " 'best': 1.4471580313422192,\n",
       " 'blood': 1.4471580313422192,\n",
       " 'bombing': 1.4471580313422192,\n",
       " 'but': 3.3803921600570273,\n",
       " 'can': 1.4471580313422192,\n",
       " 'cares': 1.4471580313422192,\n",
       " 'country': 1.4471580313422192,\n",
       " 'danger': 1.4471580313422192,\n",
       " 'days': 1.4471580313422192,\n",
       " 'death': 1.4471580313422192,\n",
       " 'defeat': 1.4471580313422192,\n",
       " 'dis': 1.4471580313422192,\n",
       " 'done': 1.4471580313422192,\n",
       " 'escape': 1.4471580313422192,\n",
       " 'extremism': 1.4471580313422192,\n",
       " 'for': 1.4471580313422192,\n",
       " 'fought': 2.2922560713564759,\n",
       " 'frenchman': 2.2922560713564759,\n",
       " 'from': 2.2922560713564759,\n",
       " 'front': 1.4471580313422192,\n",
       " 'gaal': 1.4471580313422192,\n",
       " 'get': 1.4471580313422192,\n",
       " 'girl': 1.4471580313422192,\n",
       " 'got': 1.4471580313422192,\n",
       " 'gov': 1.4471580313422192,\n",
       " \"gov't\": 1.4471580313422192,\n",
       " 'guess': 1.4471580313422192,\n",
       " 'has': 1.4471580313422192,\n",
       " 'have': 1.4471580313422192,\n",
       " 'homs': 1.4471580313422192,\n",
       " 'https://t.co/7upxsezter': 1.4471580313422192,\n",
       " 'https://t.co/8hbyib7kbb': 1.4471580313422192,\n",
       " 'https://t.co/bob8ameh2q': 1.4471580313422192,\n",
       " 'https://t.co/czadiglept': 1.4471580313422192,\n",
       " 'https://t.co/gz0wcnkrqw|v.l': 1.4471580313422192,\n",
       " 'https://t.co/ju8qdadkh1': 1.4471580313422192,\n",
       " 'https://t.co/m8eeen54td': 1.4471580313422192,\n",
       " 'https://t.co/mkoj4uisbz': 1.4471580313422192,\n",
       " 'https://t.co/mlywljrxcz': 1.4471580313422192,\n",
       " 'https://t.co/peavqp2u8f': 1.4471580313422192,\n",
       " 'https://t.co/pwayryknaf': 1.4471580313422192,\n",
       " 'https://t.co/u2pubd5lrf': 1.4471580313422192,\n",
       " 'https://t.co/vjgd9nfwww': 1.4471580313422192,\n",
       " 'i': 1.4471580313422192,\n",
       " 'identified': 2.2922560713564759,\n",
       " 'idlib': 1.4471580313422192,\n",
       " 'if': 1.4471580313422192,\n",
       " 'important': 1.4471580313422192,\n",
       " 'in': 4.0140406857514535,\n",
       " 'iran': 1.4471580313422192,\n",
       " 'is': 3.3803921600570273,\n",
       " 'isis': 1.4471580313422192,\n",
       " 'islamic': 1.4471580313422192,\n",
       " \"it's\": 1.4471580313422192,\n",
       " 'its': 1.4471580313422192,\n",
       " 'just': 1.4471580313422192,\n",
       " \"let's\": 1.4471580313422192,\n",
       " 'lives': 1.4471580313422192,\n",
       " 'manage': 1.4471580313422192,\n",
       " 'matter': 1.4471580313422192,\n",
       " 'militants': 1.4471580313422192,\n",
       " 'muslims': 1.4471580313422192,\n",
       " 'needed': 1.4471580313422192,\n",
       " 'neighborhood': 1.4471580313422192,\n",
       " 'new': 1.4471580313422192,\n",
       " 'no': 1.4471580313422192,\n",
       " 'none': 1.4471580313422192,\n",
       " 'not': 2.9101103298676705,\n",
       " 'nothing': 1.4471580313422192,\n",
       " 'obviously': 1.4471580313422192,\n",
       " 'of': 2.9101103298676705,\n",
       " 'on': 1.4471580313422192,\n",
       " 'one': 1.4471580313422192,\n",
       " 'only': 1.4471580313422192,\n",
       " 'open': 1.4471580313422192,\n",
       " 'opinion': 1.4471580313422192,\n",
       " 'over': 1.4471580313422192,\n",
       " 'paris': 1.4471580313422192,\n",
       " 'party': 1.4471580313422192,\n",
       " 'people': 2.2922560713564759,\n",
       " 'people:': 2.8943160626844384,\n",
       " 'phone': 1.4471580313422192,\n",
       " 'pm': 1.4471580313422192,\n",
       " 'policy': 1.4471580313422192,\n",
       " 'public': 1.4471580313422192,\n",
       " 'refugees': 1.4471580313422192,\n",
       " 'river': 1.4471580313422192,\n",
       " 'role': 1.4471580313422192,\n",
       " 'rt': 4.2144199392957367,\n",
       " 'said': 1.4471580313422192,\n",
       " 'side': 1.4471580313422192,\n",
       " 'signatures': 1.4471580313422192,\n",
       " 'so': 1.4471580313422192,\n",
       " 'stop': 1.4471580313422192,\n",
       " 'story': 2.8943160626844384,\n",
       " 'syria': 4.3525443548022054,\n",
       " 'syria:': 1.4471580313422192,\n",
       " 'taken': 1.4471580313422192,\n",
       " 'that': 1.4471580313422192,\n",
       " 'the': 5.820220659735341,\n",
       " 'their': 1.4471580313422192,\n",
       " 'these': 1.4471580313422192,\n",
       " 'third': 2.2922560713564759,\n",
       " 'this': 2.2922560713564759,\n",
       " 'those': 1.4471580313422192,\n",
       " 'to': 4.8164799306236992,\n",
       " 'torn': 1.4471580313422192,\n",
       " 'trump': 2.2922560713564759,\n",
       " 'trying': 1.4471580313422192,\n",
       " 'united': 1.4471580313422192,\n",
       " 'van': 1.4471580313422192,\n",
       " 'vetted': 1.4471580313422192,\n",
       " 'waer': 1.4471580313422192,\n",
       " 'want': 1.4471580313422192,\n",
       " 'war': 3.8801471064902273,\n",
       " 'we': 2.2922560713564759,\n",
       " 'weapons': 1.4471580313422192,\n",
       " 'white': 2.8943160626844384,\n",
       " 'who': 3.3803921600570273,\n",
       " 'will': 2.2922560713564759,\n",
       " 'win': 1.4471580313422192,\n",
       " 'winner': 1.4471580313422192}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Multiply the term frequency for each of the term by corresponding inverse document frequency.\n",
    "\n",
    "def tfidf(tf_dict, idf_dict):\n",
    "    tfidf_dict = {}\n",
    "    for term in tf_dict.keys():\n",
    "        tfidf_dict[term] = tf_dict[term] * idf_dict[term]\n",
    "    return tfidf_dict\n",
    "\n",
    "tfidf = tfidf(tf, idf)\n",
    "print 'Term Frequency - Inverse Document Frequency:\\n\\n'\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Sort the terms in the descending order based on their term freq/inverse document freq scores\n",
    "\n",
    "freqScore = pd.DataFrame(tfidf.items(),columns=['Term','TF-IDF']).sort(ascending=False,columns=['TF-IDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>the</td>\n",
       "      <td>5.820221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to</td>\n",
       "      <td>4.816480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>syria</td>\n",
       "      <td>4.352544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rt</td>\n",
       "      <td>4.214420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>in</td>\n",
       "      <td>4.014041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>war</td>\n",
       "      <td>3.880147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>a</td>\n",
       "      <td>3.880147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>#syria</td>\n",
       "      <td>3.740940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>but</td>\n",
       "      <td>3.380392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>is</td>\n",
       "      <td>3.380392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term    TF-IDF\n",
       "159     the  5.820221\n",
       "17       to  4.816480\n",
       "75    syria  4.352544\n",
       "49       rt  4.214420\n",
       "127      in  4.014041\n",
       "99      war  3.880147\n",
       "150       a  3.880147\n",
       "109  #syria  3.740940\n",
       "103     but  3.380392\n",
       "122      is  3.380392"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 terms\n",
    "freqScore.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
