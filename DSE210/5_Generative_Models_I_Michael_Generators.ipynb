{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 5 Generative models I \n",
    "# author: Michael Galarnyk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_data(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data_dic = {}\n",
    "        increment = 0\n",
    "        for line in f:\n",
    "            doc_word_count_gen = (int(i) for i in line.split()) # generator comprehension\n",
    "            doc_id = next(doc_word_count_gen)\n",
    "            word_id = next(doc_word_count_gen)\n",
    "            count = next(doc_word_count_gen)\n",
    "            data_dic[increment] =  [doc_id, word_id, count] \n",
    "            increment +=1\n",
    "        data_dic = np.array(data_dic.values())\n",
    "    return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_labels(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        label_list = [0]\n",
    "        classify = [0 for i in xrange(21)]\n",
    "        for line in f:\n",
    "            label_list.append(int(line))\n",
    "            classify[int(line)] += 1\n",
    "        classify = map(lambda x: 1.0 * x / len(label_list), classify)\n",
    "        label_array = np.array(label_list)\n",
    "        pi = np.array(classify)\n",
    "        pi[0] = 1.0\n",
    "        pi = np.log2(pi)\n",
    "    return label_array, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_multinomial_model(label, data):\n",
    "    m = np.zeros((21, 61189))\n",
    "    len_data = data.shape[0]\n",
    "    for i in range(len_data):\n",
    "        data_iter = iter(data[i])\n",
    "        doc_id = next(data_iter)\n",
    "        word_id = next(data_iter)\n",
    "        count = next(data_iter)\n",
    "        classify = label[doc_id]\n",
    "        m[classify][word_id] += count\n",
    "    # Remove stop words\n",
    "    stop_word = {12:\"of\", 23:\"and\",139:\"an\",978:\"am\",297:\"at\",51:\"but\",52:\"with\",33:\"to\",48:\"on\",27:\"are\",29:\"the\",72:\"can\",1367:\"else\",81:\"for\",301:\"he\",389:\"she\",99:\"so\"}\n",
    "    for k in stop_word:\n",
    "        m[:, k] = 0.0\n",
    "    m += 1\n",
    "    m[:,0] = 0.0\n",
    "    s = np.sum(m, axis = 1)\n",
    "    s_trans = np.transpose([s])\n",
    "    m = m / s_trans\n",
    "    m[:,0] = 1.0\n",
    "    m = np.log2(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop words list from sklearn \n",
    "# https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/stop_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes(m, pi, test_data, test_label):\n",
    "    len_test_data = test_data.shape[0]\n",
    "    number_doc_plus_1 = len(test_label)\n",
    "    test_m = np.zeros((number_doc_plus_1, 61189))\n",
    "    for i in range(len_test_data):\n",
    "        data_iter = iter(test_data[i])\n",
    "        doc_id = next(data_iter)\n",
    "        word_id = next(data_iter)\n",
    "        count = next(data_iter)\n",
    "        test_m[doc_id][word_id] += count\n",
    "\n",
    "    test_m = np.log2(1+test_m)\n",
    "    error = 0\n",
    "    for i in xrange(1, number_doc_plus_1):\n",
    "        cur_doc = test_m[i]\n",
    "        cur_s = np.sum(cur_doc * m, axis = 1)\n",
    "        final = cur_s + pi\n",
    "        final = final[1:]\n",
    "        label = np.argmax(final) + 1\n",
    "        if label != test_label[i]:\n",
    "            error += 1\n",
    "    return error * 100.0 / (number_doc_plus_1 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate:  20.546302465\n"
     ]
    }
   ],
   "source": [
    "path = '20news-bydate/matlab/'\n",
    "label_array, pi = read_labels('20news-bydate/matlab/train.label')\n",
    "data_array = get_data('20news-bydate/matlab/train.data')\n",
    "m = setup_multinomial_model(label_array, data_array)\n",
    "\n",
    "test_label, _ = read_labels('20news-bydate/matlab/test.label')\n",
    "test_data = get_data('20news-bydate/matlab/test.data')\n",
    "\n",
    "err = naive_bayes(m, pi, test_data, test_label)\n",
    "print \"Error Rate: \", err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
